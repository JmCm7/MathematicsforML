{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Selecting between models.\n",
        "---\n",
        "Jose Miguel Contreras Mantilla\n",
        "\n",
        "Undergraduate Math Student, Universidad Nacional de Colombia.\n",
        "\n",
        "Mathematics for Machine Learning.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "In thi notebook we will work with the datasets from:\n",
        "\n",
        "https://archive.ics.uci.edu/ml/datasets/banknote+authentication\n",
        "\n",
        "https://archive.ics.uci.edu/ml/datasets/Occupancy+Detection+\n",
        "\n",
        "And will try to select a learning model between a set of 4 or 5 five of them, which we hope, is the best to solve each problem. Finally we will test our selected Model.\n",
        "\n",
        "First we import the libraries we will use."
      ],
      "metadata": {
        "id": "zFK5R2D-aaUc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qIXVoN-yaU6e"
      },
      "outputs": [],
      "source": [
        "# Basic libraries.\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "import urllib.request\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "\n",
        "# Optimization\n",
        "from scipy.optimize import linprog\n",
        "\n",
        "# Machine Learning Models and Metrics.\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn import svm\n",
        "from sklearn import neighbors\n",
        "from sklearn import tree\n",
        "\n",
        "# Visualization libraries.\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import style\n",
        "style.use('ggplot')\n",
        "import plotly.express as px\n",
        "from plotly.offline import plot\n",
        "from plotly.subplots import make_subplots"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we save the data from the two problems we want to check, and split it between different kind of sets. Here we will consider three type of sets for boh problems: \n",
        "* A training set: We will use the data from this set to train our models. (All models will use this set)\n",
        "* A first test set: We will use the data from this set to compare the accuracy of our different models. (All models will use this set)\n",
        "* A second test set: We will use the data from this set to check the accuracy of the model we selected using the information of the previous test. Only one model will use this data in each problem."
      ],
      "metadata": {
        "id": "00eLSsa_rcqj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/00267/data_banknote_authentication.txt\", \n",
        "                 sep = ',', \n",
        "                 header = None, \n",
        "                 names=[\"variance_of_Wavelet\",\"skewness_of_Wavelet\",\n",
        "                        \"curtosis_of_Wavelet\",\"entropy\",\n",
        "                        \"class\"],\n",
        "                 thousands = ',')\n",
        "variables=[\"date\",\"temperature\", \"curtosis_of_Wavelet\",\"entropy\"]\n",
        "\n",
        "\n",
        "train_set_df, test_set_df= train_test_split(df, test_size=0.3,random_state=42)\n",
        "\n",
        "test_set_df1,test_set_df2=train_test_split(test_set_df,test_size=0.5,random_state=42)\n",
        "\n",
        "#Definition of the features X and the labels y for training\n",
        "X=train_set_df[['variance_of_Wavelet', 'skewness_of_Wavelet', 'curtosis_of_Wavelet','entropy']]\n",
        "y=train_set_df[\"class\"]\n",
        "#df.keys()\n",
        "\n",
        " #Definition of the features X_test and the labels y_test for testing 1\n",
        "X_test1=test_set_df1[['variance_of_Wavelet', 'skewness_of_Wavelet', 'curtosis_of_Wavelet','entropy']]\n",
        "y_test1=test_set_df1['class']\n",
        "\n",
        "X_test2=test_set_df2[['variance_of_Wavelet', 'skewness_of_Wavelet', 'curtosis_of_Wavelet','entropy']]\n",
        "y_test2=test_set_df2['class']\n"
      ],
      "metadata": {
        "id": "6wkT4v1pcimz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dateparse = lambda x: datetime.strptime(x, '%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "def load_occupancy_data():\n",
        "    tarball_path = Path(\"datasets/occupancy_data.zip\")\n",
        "    if not tarball_path.is_file():\n",
        "        Path(\"datasets\").mkdir(parents=True, exist_ok=True)\n",
        "        url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00357/occupancy_data.zip\"\n",
        "        urllib.request.urlretrieve(url, tarball_path)\n",
        "        with zipfile.ZipFile(tarball_path) as occupancy_tarball:\n",
        "           # open the csv file in the dataset\n",
        "           occupancy_tarball.extractall(path=\"datasets\")\n",
        "    list_df =[pd.read_csv(Path(\"datasets/datatraining.txt\"),parse_dates=['date'],date_parser=dateparse),\n",
        "              pd.read_csv(Path(\"datasets/datatest.txt\"),parse_dates=['date'],date_parser=dateparse),\n",
        "              pd.read_csv(Path(\"datasets/datatest2.txt\"),parse_dates=['date'],date_parser=dateparse),]\n",
        "    return list_df\n",
        "\n",
        "train, test1, test2= load_occupancy_data()\n",
        "\n",
        "train['date_numeric'] = train['date'].apply(lambda time: time.year+time.month/12+ time.day/365 + time.hour/8760+time.minute/525600)\n",
        "test1['date_numeric'] = test1['date'].apply(lambda time: time.year+time.month/12+ time.day/365 + time.hour/8760+time.minute/525600)\n",
        "test2['date_numeric'] = test2['date'].apply(lambda time: time.year+time.month/12+ time.day/365 + time.hour/8760+time.minute/525600)\n",
        "\n",
        "X_train_o=train[['date_numeric', 'Temperature', 'Humidity', 'Light', 'CO2', 'HumidityRatio']]\n",
        "y_train_o=train['Occupancy']\n",
        "\n",
        "X_test1_o=test1[['date_numeric', 'Temperature', 'Humidity', 'Light', \n",
        "              'CO2', 'HumidityRatio']]\n",
        "y_test1_o=test1['Occupancy']\n",
        "\n",
        "X_test2_o=test2[['date_numeric', 'Temperature', 'Humidity', 'Light', \n",
        "              'CO2', 'HumidityRatio']]\n",
        "y_test2_o=test2['Occupancy']\n",
        "\n"
      ],
      "metadata": {
        "id": "ZUwNMJtSfllh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will train our learning models using the training set. Here we will use: SVM, perceptron, K-nearest neighborhoods (with uniform and distance related weights) and decision-trees.\n",
        "\n",
        "Now we will work with de first problem:"
      ],
      "metadata": {
        "id": "IZu0yUDgt6et"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf_p = Perceptron(tol=1e-3, random_state=0)\n",
        "clf= svm.SVC()\n",
        "clf_t=tree.DecisionTreeClassifier()\n",
        "n_neighbors=15\n",
        "\n",
        "#For the banknote problem\n",
        "print(\"Working with the banknote dataset:\")\n",
        "print(\"Using the perceptron model:\")\n",
        "clf_p.fit(X, y)\n",
        "print('Accuracy training set:')\n",
        "clf_p.score(X, y)\n",
        "\n",
        "predicted_perceptron_test1=clf_p.predict(X_test1)\n",
        "print('Accuracy testing set 1:')\n",
        "clf_p.score(X_test1, y_test1)\n",
        "print(accuracy_score(y_test1, predicted_perceptron_test1).round(2))\n",
        "conf_matrix_test1= confusion_matrix(y_test1, predicted_perceptron_test1)\n",
        "#print('Acuracy:',accuracy_test1_o)\n",
        "print('Confusion matrix:\\n', conf_matrix_test1)\n",
        "\n",
        "print(\"Using the SVM model:\")\n",
        "clf.fit(X, y)\n",
        "print('Accuracy training set:')\n",
        "clf.score(X, y)\n",
        "\n",
        "predicted_svm_test1=clf.predict(X_test1)\n",
        "print('Accuracy testing set 1:')\n",
        "clf.score(X_test1, y_test1)\n",
        "print(accuracy_score(y_test1, predicted_svm_test1).round(2))\n",
        "conf_matrix_test1= confusion_matrix(y_test1, predicted_svm_test1)\n",
        "#print('Acuracy:',accuracy_test1_o)\n",
        "print('Confusion matrix:\\n', conf_matrix_test1)\n",
        "\n",
        "\n",
        "for weights in [\"uniform\", \"distance\"]:\n",
        "    print(\" Using the K-nearest neighborhood with \", weights , \"weights\") \n",
        "    # we create an instance of Neighbours Classifier and fit the data.\n",
        "    clf_k = neighbors.KNeighborsClassifier(n_neighbors, weights=weights)\n",
        "    clf_k.fit(X, y)\n",
        "    print('Accuracy training set:')\n",
        "    clf_k.score(X, y)\n",
        "\n",
        "    predicted_k_test1=clf_k.predict(X_test1)\n",
        "    print('Accuracy testing set 1:')\n",
        "    clf_k.score(X_test1, y_test1)\n",
        "    print(accuracy_score(y_test1, predicted_k_test1).round(2))\n",
        "    conf_matrix_test1= confusion_matrix(y_test1, predicted_k_test1)\n",
        "    #print('Acuracy:',accuracy_test1_o)\n",
        "    print('Confusion matrix:\\n', conf_matrix_test1)\n",
        "\n",
        "print(\"Using the Decision tree model:\")\n",
        "clf_t.fit(X, y)\n",
        "print('Accuracy training set:')\n",
        "clf_t.score(X, y)\n",
        "\n",
        "predicted_tree_test1=clf_t.predict(X_test1)\n",
        "print('Accuracy testing set 1:')\n",
        "clf_t.score(X_test1, y_test1)\n",
        "print(accuracy_score(y_test1, predicted_tree_test1).round(2))\n",
        "conf_matrix_test1= confusion_matrix(y_test1, predicted_tree_test1)\n",
        "#print('Acuracy:',accuracy_test1_o)\n",
        "print('Confusion matrix:\\n', conf_matrix_test1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFY9Fg-kf_87",
        "outputId": "a35e5e1b-9668-4d59-c1bb-7fc393a5aa65"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working with the banknote dataset:\n",
            "Using the perceptron model:\n",
            "Accuracy training set:\n",
            "Accuracy testing set 1:\n",
            "0.99\n",
            "Confusion matrix:\n",
            " [[121   1]\n",
            " [  2  82]]\n",
            "Using the SVM model:\n",
            "Accuracy training set:\n",
            "Accuracy testing set 1:\n",
            "1.0\n",
            "Confusion matrix:\n",
            " [[122   0]\n",
            " [  0  84]]\n",
            " Using the K-nearest neighborhood with  uniform weights\n",
            "Accuracy training set:\n",
            "Accuracy testing set 1:\n",
            "1.0\n",
            "Confusion matrix:\n",
            " [[122   0]\n",
            " [  0  84]]\n",
            " Using the K-nearest neighborhood with  distance weights\n",
            "Accuracy training set:\n",
            "Accuracy testing set 1:\n",
            "1.0\n",
            "Confusion matrix:\n",
            " [[122   0]\n",
            " [  0  84]]\n",
            "Using the Decision tree model:\n",
            "Accuracy training set:\n",
            "Accuracy testing set 1:\n",
            "0.99\n",
            "Confusion matrix:\n",
            " [[122   0]\n",
            " [  2  82]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can conclude form the information, that we get from the code that the perceptron model and the decision tree model aren't the ones we are looking for. Then we have to choose between svm, and k-nearest neighborhood. Trying to find a way to decide betwwen them we look in their behavior with the trainind data:"
      ],
      "metadata": {
        "id": "Jp53ZFPhFO0S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_svm= clf.predict(X)\n",
        "print(\"Acurracy with the trainin data for svm:\", accuracy_score(y, predicted_svm).round(2))\n",
        "for weights in [\"uniform\", \"distance\"]:\n",
        "    print(\" Using the K-nearest neighborhood with \", weights , \"weights\") \n",
        "    # we create an instance of Neighbours Classifier and fit the data.\n",
        "    clf_k = neighbors.KNeighborsClassifier(n_neighbors, weights=weights)\n",
        "    clf_k.fit(X, y)\n",
        "    predicted_k=clf_k.predict(X)\n",
        "    print('Accuracy training set:', accuracy_score(y, predicted_k).round(2))\n",
        "    \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-BZjrd8GHOy",
        "outputId": "19b78bb6-7923-4c9e-dfdb-1096576908c5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurracy with the trainin data for svm: 0.99\n",
            " Using the K-nearest neighborhood with  uniform weights\n",
            "Accuracy training set: 1.0\n",
            " Using the K-nearest neighborhood with  distance weights\n",
            "Accuracy training set: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally we observe that the models which predicted better the test1 data and fit better the training data where the k-nearest neighborhood models. Finally we will select the k-nearest neighborhood model using uniform weights considering the problem we are working in. We will test how good was our selection with the test2 dataset:"
      ],
      "metadata": {
        "id": "B79aLjz5HAvs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#train2\n",
        "clf_k= neighbors.KNeighborsClassifier(n_neighbors, weights=\"uniform\")\n",
        "predicted_k_test2=clf_p.predict(X_test2)\n",
        "print('Accuracy testing set 2:')\n",
        "clf_p.score(X_test2, y_test2)\n",
        "\n",
        "#accuracy_test2_o= accuracy_score(y_test2_o, predicted_perceptron_test2_o).round(2)\n",
        "conf_matrix_test2= confusion_matrix(y_test2, predicted_k_test2)\n",
        "#print('Acuracy:',accuracy_test2_o)\n",
        "print('Confusion matrix:\\n', conf_matrix_test2)\n",
        "print('Accuracy testing set 2:')\n",
        "clf_t.score(X_test2, y_test2)\n",
        "print(accuracy_score(y_test2, predicted_k_test2).round(2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kPp1iVgE13O",
        "outputId": "a5babf59-07f7-4f3c-82a6-cabe45bd1fa1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy testing set 2:\n",
            "Confusion matrix:\n",
            " [[103   4]\n",
            " [  1  98]]\n",
            "Accuracy testing set 2:\n",
            "0.98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally the model we stay with it is the K-nearest neighborhood with uniform weights, and we can observe that ir has an acurracy of 98% in the test 2 dataset, which it is pretty good.\n",
        "\n",
        "\n",
        "Now we will repeat this process with the dataset from the second problem."
      ],
      "metadata": {
        "id": "f8gJvth09CG0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf_p = Perceptron(tol=1e-3, random_state=0)\n",
        "clf= svm.SVC()\n",
        "clf_t=tree.DecisionTreeClassifier()\n",
        "n_neighbors=15\n",
        "\n",
        "#For the banknote problem\n",
        "print(\"Working with the banknote dataset:\")\n",
        "print(\"Using the perceptron model:\")\n",
        "clf_p.fit(X_train_o, y_train_o)\n",
        "print('Accuracy training set:')\n",
        "clf_p.score(X_train_o, y_train_o)\n",
        "\n",
        "predicted_perceptron_test1_o=clf_p.predict(X_test1_o)\n",
        "print('Accuracy testing set 1:')\n",
        "clf_p.score(X_test1_o, y_test1_o)\n",
        "print(accuracy_score(y_test1_o, predicted_perceptron_test1_o).round(2))\n",
        "conf_matrix_test1= confusion_matrix(y_test1_o, predicted_perceptron_test1_o)\n",
        "#print('Acuracy:',accuracy_test1_o)\n",
        "print('Confusion matrix:\\n', conf_matrix_test1)\n",
        "\n",
        "print(\"Using the SVM model:\")\n",
        "clf.fit(X_train_o, y_train_o)\n",
        "print('Accuracy training set:')\n",
        "clf.score(X_train_o, y_train_o)\n",
        "\n",
        "predicted_svm_test1=clf.predict(X_test1_o)\n",
        "print('Accuracy testing set 1:')\n",
        "clf.score(X_test1_o, y_test1_o)\n",
        "print(accuracy_score(y_test1_o, predicted_svm_test1).round(2))\n",
        "conf_matrix_test1= confusion_matrix(y_test1_o, predicted_svm_test1)\n",
        "#print('Acuracy:',accuracy_test1_o)\n",
        "print('Confusion matrix:\\n', conf_matrix_test1)\n",
        "\n",
        "\n",
        "for weights in [\"uniform\", \"distance\"]:\n",
        "    print(\" Using the K-nearest neighborhood with \", weights , \"weights\") \n",
        "    # we create an instance of Neighbours Classifier and fit the data.\n",
        "    clf_k = neighbors.KNeighborsClassifier(n_neighbors, weights=weights)\n",
        "    clf_k.fit(X_train_o, y_train_o)\n",
        "    print('Accuracy training set:')\n",
        "    clf_k.score(X_train_o, y_train_o)\n",
        "\n",
        "    predicted_k_test1=clf_k.predict(X_test1_o)\n",
        "    print('Accuracy testing set 1:')\n",
        "    clf_k.score(X_test1_o, y_test1_o)\n",
        "    print(accuracy_score(y_test1_o, predicted_k_test1).round(2))\n",
        "    conf_matrix_test1= confusion_matrix(y_test1_o, predicted_k_test1)\n",
        "    #print('Acuracy:',accuracy_test1_o)\n",
        "    print('Confusion matrix:\\n', conf_matrix_test1)\n",
        "\n",
        "print(\"Using the Decision tree model:\")\n",
        "clf_t.fit(X_train_o, y_train_o)\n",
        "print('Accuracy training set:')\n",
        "clf_t.score(X_train_o, y_train_o)\n",
        "\n",
        "predicted_tree_test1=clf_t.predict(X_test1_o)\n",
        "print('Accuracy testing set 1:')\n",
        "clf_t.score(X_test1_o, y_test1_o)\n",
        "print(accuracy_score(y_test1_o, predicted_tree_test1).round(2))\n",
        "conf_matrix_test1= confusion_matrix(y_test1_o, predicted_tree_test1)\n",
        "#print('Acuracy:',accuracy_test1_o)\n",
        "print('Confusion matrix:\\n', conf_matrix_test1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLo92IEX9_3u",
        "outputId": "b61b7319-a239-4cd0-d87b-307faec90873"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working with the banknote dataset:\n",
            "Using the perceptron model:\n",
            "Accuracy training set:\n",
            "Accuracy testing set 1:\n",
            "0.95\n",
            "Confusion matrix:\n",
            " [[1648   45]\n",
            " [  79  893]]\n",
            "Using the SVM model:\n",
            "Accuracy training set:\n",
            "Accuracy testing set 1:\n",
            "0.98\n",
            "Confusion matrix:\n",
            " [[1641   52]\n",
            " [  13  959]]\n",
            " Using the K-nearest neighborhood with  uniform weights\n",
            "Accuracy training set:\n",
            "Accuracy testing set 1:\n",
            "0.97\n",
            "Confusion matrix:\n",
            " [[1643   50]\n",
            " [  31  941]]\n",
            " Using the K-nearest neighborhood with  distance weights\n",
            "Accuracy training set:\n",
            "Accuracy testing set 1:\n",
            "0.96\n",
            "Confusion matrix:\n",
            " [[1644   49]\n",
            " [  50  922]]\n",
            "Using the Decision tree model:\n",
            "Accuracy training set:\n",
            "Accuracy testing set 1:\n",
            "0.87\n",
            "Confusion matrix:\n",
            " [[1668   25]\n",
            " [ 323  649]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this case there is a higher difference among the values of the accuracy in each model for the data set of test 1. However we can see that the one, which predicts the new data with better precision is the model of SVM. We will select this one as our final model, and check how well is his behavior usinf the dataset Test 2."
      ],
      "metadata": {
        "id": "zUq6jBD1_p7U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_svm_test2=clf.predict(X_test2_o)\n",
        "print('Accuracy testing set 2:')\n",
        "clf_p.score(X_test2_o, y_test2_o)\n",
        "\n",
        "#accuracy_test2_o= accuracy_score(y_test2_o, predicted_perceptron_test2_o).round(2)\n",
        "conf_matrix_test2= confusion_matrix(y_test2_o, predicted_svm_test2)\n",
        "#print('Acuracy:',accuracy_test2_o)\n",
        "print('Confusion matrix:\\n', conf_matrix_test2)\n",
        "print('Accuracy testing set 2:')\n",
        "clf_t.score(X_test2_o, y_test2_o)\n",
        "print(accuracy_score(y_test2_o, predicted_svm_test2).round(2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uf79Z7UWAgh4",
        "outputId": "8a32947c-3a68-4d86-e0bd-029a8ec57b2c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy testing set 2:\n",
            "Confusion matrix:\n",
            " [[7566  137]\n",
            " [   8 2041]]\n",
            "Accuracy testing set 2:\n",
            "0.99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that we ended up with an even better accuracy in the dataset of test 2, using the SVM than the accuracy in the dataset of test 1 with the same model. That really good, and give us certain degree of confidence in our selection.\n",
        "\n",
        "#References:\n",
        "\n",
        "\n",
        "*   https://scikit-learn.org/stable/modules/tree.html\n",
        "*   https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
        "*   https://scikit-learn.org/stable/modules/neighbors.html\n",
        "*  https://scikit-learn.org/stable/modules/svm.html\n"
      ],
      "metadata": {
        "id": "pWUMEoqFBFyE"
      }
    }
  ]
}